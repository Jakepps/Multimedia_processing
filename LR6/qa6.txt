1. Опишите принцип обучения нейронной сети с учителем.
* Принцип обучения нейронной сети с учителем:
Обучение нейронной сети с учителем заключается в обучении модели на основе пар входных данных и соответствующих
этим данным выходных целевых значений (так называемых меток). Модель старается научиться преобразовывать входные 
данные в соответствующие целевые значения.
* Процесс обучения включает в себя следующие шаги: подача входных данных в модель, вычисление прогнозов модели, 
вычисление ошибки между прогнозами и целевыми значениями, и обновление параметров модели с целью минимизации этой ошибки. 
Этот процесс может повторяться на протяжении нескольких эпох до достижения приемлемого уровня точности.

2. Опишите структуру нейрона.
* Нейрон состоит из трех основных компонентов: входов, весов и функции активации.
Входы представляют входные сигналы, веса - параметры, которые моделируют силу связей между входами и нейроном, 
и функция активации определяет, какой выход будет сгенерирован на основе входов и весов.
* Математически, выход нейрона можно выразить как взвешенную сумму входов, обработанную функцией активации: 
Выход = Функция_Активации(Σ(Вход * Вес)).

3. Опишите структуру персептрона.
* Персептрон - это простейший вид нейрона в искусственных нейронных сетях. 
Он имеет несколько входов, веса для каждого входа, функцию активации и один выход.
* Входы умножаются на соответствующие веса и суммируются. Затем полученная сумма подвергается функции активации.
Если значение после функции активации превышает определенный порог, персептрон активируется и выдает выходное значение, 
иначе он остается неактивным.

4. Опишите смысл применения оптимизационных методов в задачах
обучения нейронной сети.
* Оптимизационные методы используются для настройки параметров нейронной сети с целью минимизации функции потерь. 
Это позволяет нейронной сети адаптироваться к данным и улучшать свои прогнозы.
* Примеры оптимизационных методов включают в себя градиентный спуск (Gradient Descent) и его различные вариации, такие как Adam, RMSprop, и другие. 
Они регулируют скорость обучения и направление обновления весов сети на основе градиента функции потерь.

5. Что такое аугментация?
* Аугментация данных - это методика, которая заключается в генерации дополнительных обучающих примеров 
путем применения различных преобразований к существующим данным. Эти преобразования могут включать в себя повороты, 
отражения, смещения, изменение яркости и многое другое.
* Аугментация данных помогает расширить обучающий набор, что может улучшить обобщающую способность нейронной сети и 
сделать ее более устойчивой к различным условиям входных данных.

6. Опишите принцип пакетного и последовательного обучения? Что такое batch_size?
* Пакетное обучение (Batch Learning): При пакетном обучении модель обновляет свои параметры после обработки заданного 
количества образцов (пакета) за одну итерацию обучения. Это позволяет улучшить эффективность вычислений и использовать 
параллелизм на многопроцессорных системах. batch_size определяет размер пакета.

* Последовательное обучение (Sequential Learning): В последовательном обучении модель обновляет параметры после каждого образца. 
Это может быть полезно в некоторых ситуациях, но может быть менее эффективным в сравнении с пакетным обучением.

7. Покажите известные Вам функции активации.
* Сигмоидная функция (Sigmoid): f(x) = 1 / (1 + e^(-x))
* Гиперболический тангенс (Tanh): f(x) = (e^x - e^(-x)) / (e^x + e^(-x))
* ReLU (Rectified Linear Unit): f(x) = max(0, x)
* Leaky ReLU: f(x) = x, если x > 0, и f(x) = 0.01x, если x <= 0
* Softmax: Используется на выходном слое классификационных моделей для вычисления вероятностей принадлежности к каждому классу.

* ReLU (Rectified Linear Unit) - является простой нелинейной функцией, которая выполняет следующее преобразование для каждого входного значения:
Если входное значение положительное (больше или равно нулю), то ReLU оставляет его без изменений.
Если входное значение отрицательное, то ReLU заменяет его на ноль.

* Функция активации Softmax - это функция, которая используется в нейронных сетях для многоклассовой классификации. 
Она преобразует вектор значений (чаще всего выходов последнего слоя нейронной сети) в вероятностное распределение по классам. 
Softmax принимает входной вектор, и для каждого элемента вектора вычисляет вероятность, что данный элемент принадлежит 
к одному из классов. Затем эти вероятности нормализуются так, чтобы их сумма равнялась 1.

